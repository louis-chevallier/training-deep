{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classifying tiny digit images with MLP from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10-class recognition problem, one hidden layer, square loss\n",
    "- implement full-batch vectorized gradient descent\n",
    "- monitor train and test error\n",
    "- compute accuracies\n",
    "- play with parameters\n",
    "- add biases\n",
    "- change to softmax laeyr with logistic loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# main parameters\n",
    "iterNum = 5000\n",
    "stepSize = 10.0\n",
    "hiddenSize = 10\n",
    "trainNum = 500\n",
    "displayFlag = False\n",
    "\n",
    "# Display plots inline \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute sigmoid\n",
    "def sigmoid(x):\n",
    "    output = 1/(1+np.exp(-x))\n",
    "    return output\n",
    "\n",
    "# convert output of sigmoid function to its derivative\n",
    "def sigmoid_output_to_derivative(output):\n",
    "    return output*(1-output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 training examples and 1297 test examples\n"
     ]
    }
   ],
   "source": [
    "# load and prepare dataset\n",
    "digits = datasets.load_digits()\n",
    "X_all = digits.data.T\n",
    "y = digits.target\n",
    "dataNum = X_all.shape[1]\n",
    "labels = digits.target_names\n",
    "outSize = labels.size \n",
    "inputSize = X_all.shape[0]\n",
    "\n",
    "# building gt one-hot vectors \n",
    "Y_all = np.zeros((outSize,dataNum))\n",
    "for n in range(dataNum):  \n",
    "    Y_all[y[n],n] = 1 \n",
    "\n",
    "# extract training and tet sets\n",
    "testNum = dataNum - trainNum\n",
    "X = X_all[:,:trainNum]\n",
    "Y = Y_all[:,:trainNum]\n",
    "X_test = X_all[:,trainNum:]\n",
    "Y_test = Y_all[:,trainNum:]\n",
    "print('%d training examples and %d test examples' % (trainNum,testNum))\n",
    "\n",
    "# visualizing random samples\n",
    "if displayFlag:\n",
    "    tileSize = 10\n",
    "    lst_strips = []\n",
    "    for row in range(tileSize):\n",
    "        lst_imgs = []\n",
    "        ids = np.random.randint(0,dataNum,tileSize)\n",
    "        for id in ids:\n",
    "            lst_imgs.append(np.concatenate([digits.images[id],np.ones((8,2))],axis=1))\n",
    "        strip = np.concatenate(lst_imgs, axis=1)\n",
    "        lst_strips.append(np.concatenate([strip,np.ones((2,10*tileSize))],axis=0))\n",
    "    tile = np.concatenate(lst_strips, axis=0)\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(tile,interpolation='none',cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize weights randomly with mean 0\n",
    "# np.random.seed(1)\n",
    "W1 = np.random.randn(hiddenSize,inputSize)\n",
    "W2 = np.random.randn(outSize,hiddenSize)\n",
    "\n",
    "# visualize weights\n",
    "if displayFlag:\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(W1,interpolation = 'none')\n",
    "    plt.axis('off')\n",
    "    plt.title('W1')\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(W2,interpolation = 'none')\n",
    "    plt.axis('off')\n",
    "    plt.title('W2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "activation (no bias): $a_{\\ell} = Wx_{\\ell-1}$, output: $x_{\\ell} = \\sigma(a_{\\ell})$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "square loss: $\\frac{1}{2N} \\sum_{n=1}^{N} \\|x_2^{(n)}-y^{(n)}\\|^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute batch loss and loss gradient  \n",
    "def loss(pred,target): \n",
    "    return 0 # TBC\n",
    " \n",
    "def lossGrad(pred,target):\n",
    "    return 0 # TBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/test error after 0 iterations: 0.0000 / 0.0000\n",
      "Train/test error after 1000 iterations: 0.0000 / 0.0000\n",
      "Train/test error after 2000 iterations: 0.0000 / 0.0000\n",
      "Train/test error after 3000 iterations: 0.0000 / 0.0000\n",
      "Train/test error after 4000 iterations: 0.0000 / 0.0000\n"
     ]
    }
   ],
   "source": [
    "trainError = np.zeros(iterNum)\n",
    "testError = np.zeros(iterNum)\n",
    "\n",
    "for iter in range(iterNum):\n",
    "\n",
    "    # forward propagation on training and test data\n",
    "    X0 = X\n",
    "    A1 = np.dot(W1,X0)  \n",
    "    X1 = sigmoid(A1)\n",
    "    A2 = np.dot(W2,X1)\n",
    "    X2 = sigmoid(A2)    \n",
    "    \n",
    "    X2_test = np.zeros(Y_test.shape) # TBC \n",
    "    \n",
    "    # compute and print mean error on both datasets \n",
    "    trainError[iter] = np.mean(loss(X2,Y))\n",
    "    testError[iter]  = np.mean(loss(X2_test,Y_test))\n",
    "    if (iter% 1000) == 0 :\n",
    "        print(\"Train/test error after %d iterations: %.4f / %.4f\" % (iter,  trainError[iter], testError[iter]))\n",
    "   \n",
    "    # back propagation of training errors\n",
    "    G2 = lossGrad(X2,Y)\n",
    "    H2 = G2 * sigmoid_output_to_derivative(X2)\n",
    "    G1 = np.dot(W2.T,H2)\n",
    "    H1 = G1 * sigmoid_output_to_derivative(X1)\n",
    "    \n",
    "    dW1 = np.dot(H1,X0.T) / trainNum \n",
    "    dW2 = np.dot(H2,X1.T) / trainNum\n",
    "    \n",
    "    # Updating weights\n",
    "    W2 -= stepSize * dW2\n",
    "    W1 -= stepSize * dW1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.0000\n"
     ]
    }
   ],
   "source": [
    "# test accuracy\n",
    "accuracy = float(0);\n",
    "# TBC\n",
    "print('Accuracy : %.4f' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# training and test plots\n",
    "if displayFlag:\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.plot(range(iterNum),trainError,'b',range(iterNum),testError,'r',)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualize randomly picked test predictions\n",
    "if displayFlag:\n",
    "    sampleId = np.random.randint(0,testNum,5)\n",
    "    for id in sampleId:\n",
    "        if np.argmax(X2_test[:,id]) != y[id+trainNum] :\n",
    "            colormap = 'hot'\n",
    "        else: \n",
    "            colormap = 'gray'\n",
    "        plt.figure(figsize=(1,1))\n",
    "        plt.imshow(digits.images[id+trainNum],interpolation='none',cmap=colormap)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        print('true: %d, predicted: %d' % (np.argmax(X2_test[:,id]) , y[id+trainNum]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
